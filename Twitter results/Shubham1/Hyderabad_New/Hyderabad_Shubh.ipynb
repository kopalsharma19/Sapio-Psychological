{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr_No</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6/12/2020 10:43</td>\n",
       "      <td>RT @NaseerGiyas: Doctors, nurses, police offic...</td>\n",
       "      <td>FareehaM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6/12/2020 10:41</td>\n",
       "      <td>Becoz of this fallacious thinking(mismanagemen...</td>\n",
       "      <td>mizozeitgeist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6/12/2020 10:40</td>\n",
       "      <td>TS Police Not Taking Serious Action Against Th...</td>\n",
       "      <td>mursalinahme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6/12/2020 10:40</td>\n",
       "      <td>According to our Research on Covid-19 In Telan...</td>\n",
       "      <td>mursalinahme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6/12/2020 10:40</td>\n",
       "      <td>I don't even know what to say anymore. #Telang...</td>\n",
       "      <td>HariniPrasad13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sr_No             Date                                               Text  \\\n",
       "0      0  6/12/2020 10:43  RT @NaseerGiyas: Doctors, nurses, police offic...   \n",
       "1      1  6/12/2020 10:41  Becoz of this fallacious thinking(mismanagemen...   \n",
       "2      2  6/12/2020 10:40  TS Police Not Taking Serious Action Against Th...   \n",
       "3      3  6/12/2020 10:40  According to our Research on Covid-19 In Telan...   \n",
       "4      4  6/12/2020 10:40  I don't even know what to say anymore. #Telang...   \n",
       "\n",
       "             User  \n",
       "0        FareehaM  \n",
       "1   mizozeitgeist  \n",
       "2    mursalinahme  \n",
       "3    mursalinahme  \n",
       "4  HariniPrasad13  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import string\n",
    "import nltk\n",
    "import warnings \n",
    "\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('Tweets4.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from textblob) (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "import textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "    return input_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Tweets4.csv')\n",
    "data['tidy_tweet'] = np.vectorize(remove_pattern)(data['Text'], \"@[\\w]*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tidy_tweet'] = data['tidy_tweet'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "data['tidy_tweet'] = data['tidy_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr_No</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>User</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6/12/2020 10:43</td>\n",
       "      <td>RT @NaseerGiyas: Doctors, nurses, police offic...</td>\n",
       "      <td>FareehaM</td>\n",
       "      <td>doctors nurses police officials media persons ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6/12/2020 10:41</td>\n",
       "      <td>Becoz of this fallacious thinking(mismanagemen...</td>\n",
       "      <td>mizozeitgeist</td>\n",
       "      <td>becoz this fallacious thinking mismanagement s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6/12/2020 10:40</td>\n",
       "      <td>TS Police Not Taking Serious Action Against Th...</td>\n",
       "      <td>mursalinahme</td>\n",
       "      <td>police taking serious action against breakers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6/12/2020 10:40</td>\n",
       "      <td>According to our Research on Covid-19 In Telan...</td>\n",
       "      <td>mursalinahme</td>\n",
       "      <td>according research telangana telangana needs m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6/12/2020 10:40</td>\n",
       "      <td>I don't even know what to say anymore. #Telang...</td>\n",
       "      <td>HariniPrasad13</td>\n",
       "      <td>even know what anymore #telangana dies road am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sr_No             Date                                               Text  \\\n",
       "0      0  6/12/2020 10:43  RT @NaseerGiyas: Doctors, nurses, police offic...   \n",
       "1      1  6/12/2020 10:41  Becoz of this fallacious thinking(mismanagemen...   \n",
       "2      2  6/12/2020 10:40  TS Police Not Taking Serious Action Against Th...   \n",
       "3      3  6/12/2020 10:40  According to our Research on Covid-19 In Telan...   \n",
       "4      4  6/12/2020 10:40  I don't even know what to say anymore. #Telang...   \n",
       "\n",
       "             User                                         tidy_tweet  \n",
       "0        FareehaM  doctors nurses police officials media persons ...  \n",
       "1   mizozeitgeist  becoz this fallacious thinking mismanagement s...  \n",
       "2    mursalinahme  police taking serious action against breakers ...  \n",
       "3    mursalinahme  according research telangana telangana needs m...  \n",
       "4  HariniPrasad13  even know what anymore #telangana dies road am...  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words2= ['https','covid']\n",
    "\n",
    "for i in range(len(data['tidy_tweet'])):\n",
    "    data['tidy_tweet'][i]= data['tidy_tweet'][i].lower()\n",
    "    query= data['tidy_tweet'][i]\n",
    "    querywords = query.split()\n",
    "    #querywords  = [word for word in querywords if word.lower() not in stop_words]\n",
    "    resultwords  = [word for word in querywords if word.lower() not in stop_words2]\n",
    "    result = ' '.join(resultwords)\n",
    "    data['tidy_tweet'][i]= result\n",
    "    \n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol=[]\n",
    "for i in range(len(data['tidy_tweet'])):\n",
    "      blob = TextBlob(data['tidy_tweet'][i])\n",
    "      Sentiment = blob.sentiment    \n",
    "      polarity = Sentiment.polarity\n",
    "      subjectivity = Sentiment.subjectivity\n",
    "      pol.append(polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr_No</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>User</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6/12/2020 10:43</td>\n",
       "      <td>RT @NaseerGiyas: Doctors, nurses, police offic...</td>\n",
       "      <td>FareehaM</td>\n",
       "      <td>doctors nurses police officials media persons ...</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6/12/2020 10:41</td>\n",
       "      <td>Becoz of this fallacious thinking(mismanagemen...</td>\n",
       "      <td>mizozeitgeist</td>\n",
       "      <td>becoz this fallacious thinking mismanagement s...</td>\n",
       "      <td>-0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6/12/2020 10:40</td>\n",
       "      <td>TS Police Not Taking Serious Action Against Th...</td>\n",
       "      <td>mursalinahme</td>\n",
       "      <td>police taking serious action against breakers ...</td>\n",
       "      <td>-0.022222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6/12/2020 10:40</td>\n",
       "      <td>According to our Research on Covid-19 In Telan...</td>\n",
       "      <td>mursalinahme</td>\n",
       "      <td>according research telangana telangana needs m...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6/12/2020 10:40</td>\n",
       "      <td>I don't even know what to say anymore. #Telang...</td>\n",
       "      <td>HariniPrasad13</td>\n",
       "      <td>even know what anymore #telangana dies road am...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sr_No             Date                                               Text  \\\n",
       "0      0  6/12/2020 10:43  RT @NaseerGiyas: Doctors, nurses, police offic...   \n",
       "1      1  6/12/2020 10:41  Becoz of this fallacious thinking(mismanagemen...   \n",
       "2      2  6/12/2020 10:40  TS Police Not Taking Serious Action Against Th...   \n",
       "3      3  6/12/2020 10:40  According to our Research on Covid-19 In Telan...   \n",
       "4      4  6/12/2020 10:40  I don't even know what to say anymore. #Telang...   \n",
       "\n",
       "             User                                         tidy_tweet  polarity  \n",
       "0        FareehaM  doctors nurses police officials media persons ... -0.500000  \n",
       "1   mizozeitgeist  becoz this fallacious thinking mismanagement s... -0.200000  \n",
       "2    mursalinahme  police taking serious action against breakers ... -0.022222  \n",
       "3    mursalinahme  according research telangana telangana needs m...  0.000000  \n",
       "4  HariniPrasad13  even know what anymore #telangana dies road am...  0.000000  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['polarity']=pol\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sr_No</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>User</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>polarity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6/12/2020 10:43</td>\n",
       "      <td>RT @NaseerGiyas: Doctors, nurses, police offic...</td>\n",
       "      <td>FareehaM</td>\n",
       "      <td>doctors nurses police officials media persons ...</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6/12/2020 10:41</td>\n",
       "      <td>Becoz of this fallacious thinking(mismanagemen...</td>\n",
       "      <td>mizozeitgeist</td>\n",
       "      <td>becoz this fallacious thinking mismanagement s...</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6/12/2020 10:40</td>\n",
       "      <td>TS Police Not Taking Serious Action Against Th...</td>\n",
       "      <td>mursalinahme</td>\n",
       "      <td>police taking serious action against breakers ...</td>\n",
       "      <td>-0.022222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6/12/2020 10:40</td>\n",
       "      <td>According to our Research on Covid-19 In Telan...</td>\n",
       "      <td>mursalinahme</td>\n",
       "      <td>according research telangana telangana needs m...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6/12/2020 10:40</td>\n",
       "      <td>I don't even know what to say anymore. #Telang...</td>\n",
       "      <td>HariniPrasad13</td>\n",
       "      <td>even know what anymore #telangana dies road am...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sr_No             Date                                               Text  \\\n",
       "0      0  6/12/2020 10:43  RT @NaseerGiyas: Doctors, nurses, police offic...   \n",
       "1      1  6/12/2020 10:41  Becoz of this fallacious thinking(mismanagemen...   \n",
       "2      2  6/12/2020 10:40  TS Police Not Taking Serious Action Against Th...   \n",
       "3      3  6/12/2020 10:40  According to our Research on Covid-19 In Telan...   \n",
       "4      4  6/12/2020 10:40  I don't even know what to say anymore. #Telang...   \n",
       "\n",
       "             User                                         tidy_tweet  \\\n",
       "0        FareehaM  doctors nurses police officials media persons ...   \n",
       "1   mizozeitgeist  becoz this fallacious thinking mismanagement s...   \n",
       "2    mursalinahme  police taking serious action against breakers ...   \n",
       "3    mursalinahme  according research telangana telangana needs m...   \n",
       "4  HariniPrasad13  even know what anymore #telangana dies road am...   \n",
       "\n",
       "   polarity  label  \n",
       "0 -0.500000      0  \n",
       "1 -0.200000      0  \n",
       "2 -0.022222      0  \n",
       "3  0.000000      1  \n",
       "4  0.000000      1  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'] = np.where(data['polarity'] >= 0 , 1, 0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Text'], \n",
    "                                                    data['label'], \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def test1():\n",
    "    vect = CountVectorizer().fit(X_train)\n",
    "    X_train_vectorized = vect.transform(X_train)\n",
    "  \n",
    "    Nb= BernoulliNB(alpha=0.13) \n",
    "    a= Nb.fit(X_train_vectorized,y_train)\n",
    "    b=a.predict(vect.transform(X_test))\n",
    "    c= roc_auc_score(y_test,b)\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9772727272727273"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def test2():\n",
    "    vect = TfidfVectorizer(min_df=3).fit(X_train)\n",
    "    X_train_vectorized = vect.transform(X_train)\n",
    "    feature_names = np.array(vect.get_feature_names())\n",
    "    \n",
    "    Nb= MultinomialNB(alpha=0.1) \n",
    "    a= Nb.fit(X_train_vectorized,y_train)\n",
    "    b=a.predict(vect.transform(X_test))\n",
    "    c= roc_auc_score(y_test,b)\n",
    "    \n",
    "\n",
    "    \n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666667"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2()\n",
    "#Multinomial Naive bayes model is not good for this data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature(X, feature_to_add):\n",
    "    \"\"\"\n",
    "    Returns sparse feature matrix with added feature.\n",
    "    feature_to_add can also be a list of features.\n",
    "    \"\"\"\n",
    "    from scipy.sparse import csr_matrix, hstack\n",
    "    return hstack([X, csr_matrix(feature_to_add).T], 'csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def test3():\n",
    "    vectorizer = TfidfVectorizer(min_df=3)\n",
    "    X_train_transformed = vectorizer.fit_transform(X_train)\n",
    "    X_train_transformed_with_length = add_feature(X_train_transformed, X_train.str.len())\n",
    "\n",
    "    X_test_transformed = vectorizer.transform(X_test)\n",
    "    X_test_transformed_with_length = add_feature(X_test_transformed, X_test.str.len())\n",
    "\n",
    "    clf = SVC(C=10000)\n",
    "\n",
    "    clf.fit(X_train_transformed_with_length, y_train)\n",
    "\n",
    "    y_predicted = clf.predict(X_test_transformed_with_length)\n",
    "    \n",
    "    return roc_auc_score(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8106060606060607"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3()\n",
    "#Support vector machine is not as better as logistics regg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def test4():\n",
    "    import re\n",
    "\n",
    "    vect = TfidfVectorizer(min_df=3).fit(X_train)\n",
    "\n",
    "    X_train_vectorized = vect.transform(X_train)\n",
    "    X_test_vectorized= vect.transform(X_test)\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, X_train.str.len())\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, X_train.apply(lambda row: len(re.findall(r'(\\d)', row))))\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, X_test.str.len())\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, X_test.apply(lambda row: len(re.findall(r'(\\d)', row))))\n",
    "    model = LogisticRegression(C=10000)\n",
    "    fit=model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "    predictions = model.predict(X_test_vectorized)\n",
    "    \n",
    "    f1= f1_score(y_test,predictions)\n",
    "    return roc_auc_score(y_test,predictions),f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8333333333333334, 0.9777777777777777)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test5():\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import f1_score\n",
    "    \n",
    "    import re\n",
    "\n",
    "    vect = CountVectorizer(min_df=5, ngram_range=(2,5),analyzer='char_wb').fit(X_train)\n",
    "\n",
    "    X_train_vectorized = vect.transform(X_train)\n",
    "    X_test_vectorized= vect.transform(X_test)\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, X_train.str.len())\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, X_train.apply(lambda row: len(re.findall(r'(\\d)', row))))\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, X_test.str.len())\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, X_test.apply(lambda row: len(re.findall(r'(\\d)', row))))\n",
    "    X_train_vectorized = add_feature(X_train_vectorized, X_train.apply(lambda row: len(re.findall(r'(\\W)', row))))\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, X_test.apply(lambda row: len(re.findall(r'(\\W)', row))))\n",
    "    \n",
    "    \n",
    "    model=LogisticRegression(C=100)\n",
    "    \n",
    "    fit=model.fit(X_train_vectorized, y_train)\n",
    "    \n",
    "\n",
    "    predictions = model.predict(X_test_vectorized)\n",
    "    \n",
    "    feature_names = np.array(vect.get_feature_names()+['length_of_doc', 'digit_count', 'non_word_char_count'])\n",
    "\n",
    "    \n",
    "    sorted_coef_index = model.coef_[0].argsort()\n",
    "    a=feature_names[sorted_coef_index[:10]]\n",
    "    b=feature_names[sorted_coef_index[:-11:-1]]\n",
    "    c=list(a)\n",
    "    d=list(b)\n",
    "\n",
    "    acc=roc_auc_score(y_test,predictions)\n",
    "    f1= f1_score(y_test,predictions)\n",
    "    return acc,f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9772727272727273, 0.9767441860465117)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test5()\n",
    "#Logistics regression with added features is working fine\n",
    "#c=100 is hyperparameter\n",
    "#n gram checks for sequence of words so here it will check for a sequence of length 2 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
